{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-Time Sentiment Analysis of a Phone Call Using NLTK and TextBlob in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Watch Full Video Here: https://youtu.be/mprXs8IASL8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\programdata\\anaconda3\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\laxmilab\\appdata\\roaming\\python\\python37\\site-packages (from textblob) (3.4.5)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\laxmilab\\appdata\\roaming\\python\\python37\\site-packages (3.4.5)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\LaxmiLab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\LaxmiLab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob as blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = blob('Hi, please like this video!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Hi, please like this video!\")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on TextBlob in module textblob.blob object:\n",
      "\n",
      "class TextBlob(BaseBlob)\n",
      " |  TextBlob(text, tokenizer=None, pos_tagger=None, np_extractor=None, analyzer=None, parser=None, classifier=None, clean_html=False)\n",
      " |  \n",
      " |  A general text block, meant for larger bodies of text (esp. those\n",
      " |  containing sentences). Inherits from :class:`BaseBlob <BaseBlob>`.\n",
      " |  \n",
      " |  :param str text: A string.\n",
      " |  :param tokenizer: (optional) A tokenizer instance. If ``None``, defaults to\n",
      " |      :class:`WordTokenizer() <textblob.tokenizers.WordTokenizer>`.\n",
      " |  :param np_extractor: (optional) An NPExtractor instance. If ``None``,\n",
      " |      defaults to :class:`FastNPExtractor() <textblob.en.np_extractors.FastNPExtractor>`.\n",
      " |  :param pos_tagger: (optional) A Tagger instance. If ``None``, defaults to\n",
      " |      :class:`NLTKTagger <textblob.en.taggers.NLTKTagger>`.\n",
      " |  :param analyzer: (optional) A sentiment analyzer. If ``None``, defaults to\n",
      " |      :class:`PatternAnalyzer <textblob.en.sentiments.PatternAnalyzer>`.\n",
      " |  :param classifier: (optional) A classifier.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TextBlob\n",
      " |      BaseBlob\n",
      " |      textblob.mixins.StringlikeMixin\n",
      " |      textblob.mixins.BlobComparableMixin\n",
      " |      textblob.mixins.ComparableMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  sentences = <textblob.decorators.cached_property object>\n",
      " |  to_json(self, *args, **kwargs)\n",
      " |      Return a json representation (str) of this blob.\n",
      " |      Takes the same arguments as json.dumps.\n",
      " |      \n",
      " |      .. versionadded:: 0.5.1\n",
      " |  \n",
      " |  words = <textblob.decorators.cached_property object>\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  json\n",
      " |      The json representation of this blob.\n",
      " |      \n",
      " |      .. versionchanged:: 0.5.1\n",
      " |          Made ``json`` a property instead of a method to restore backwards\n",
      " |          compatibility that was broken after version 0.4.0.\n",
      " |  \n",
      " |  raw_sentences\n",
      " |      List of strings, the raw sentences in the blob.\n",
      " |  \n",
      " |  serialized\n",
      " |      Returns a list of each sentence's dict representation.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseBlob:\n",
      " |  \n",
      " |  __add__(self, other)\n",
      " |      Concatenates two text objects the same way Python strings are\n",
      " |      concatenated.\n",
      " |      \n",
      " |      Arguments:\n",
      " |      - `other`: a string or a text object\n",
      " |  \n",
      " |  __hash__(self)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __init__(self, text, tokenizer=None, pos_tagger=None, np_extractor=None, analyzer=None, parser=None, classifier=None, clean_html=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  classify(self)\n",
      " |      Classify the blob using the blob's ``classifier``.\n",
      " |  \n",
      " |  correct(self)\n",
      " |      Attempt to correct the spelling of a blob.\n",
      " |      \n",
      " |      .. versionadded:: 0.6.0\n",
      " |      \n",
      " |      :rtype: :class:`BaseBlob <BaseBlob>`\n",
      " |  \n",
      " |  detect_language(self)\n",
      " |      Detect the blob's language using the Google Translate API.\n",
      " |      \n",
      " |      Requires an internet connection.\n",
      " |      \n",
      " |      Usage:\n",
      " |      ::\n",
      " |      \n",
      " |          >>> b = TextBlob(\"bonjour\")\n",
      " |          >>> b.detect_language()\n",
      " |          u'fr'\n",
      " |      \n",
      " |      Language code reference:\n",
      " |          https://developers.google.com/translate/v2/using_rest#language-params\n",
      " |      \n",
      " |      .. versionadded:: 0.5.0\n",
      " |      \n",
      " |      :rtype: str\n",
      " |  \n",
      " |  ngrams(self, n=3)\n",
      " |      Return a list of n-grams (tuples of n successive words) for this\n",
      " |      blob.\n",
      " |      \n",
      " |      :rtype: List of :class:`WordLists <WordList>`\n",
      " |  \n",
      " |  noun_phrases = <textblob.decorators.cached_property object>\n",
      " |  np_counts = <textblob.decorators.cached_property object>\n",
      " |  parse(self, parser=None)\n",
      " |      Parse the text.\n",
      " |      \n",
      " |      :param parser: (optional) A parser instance. If ``None``, defaults to\n",
      " |          this blob's default parser.\n",
      " |      \n",
      " |      .. versionadded:: 0.6.0\n",
      " |  \n",
      " |  polarity = <textblob.decorators.cached_property object>\n",
      " |  pos_tags = <textblob.decorators.cached_property object>\n",
      " |  sentiment = <textblob.decorators.cached_property object>\n",
      " |  sentiment_assessments = <textblob.decorators.cached_property object>\n",
      " |  split(self, sep=None, maxsplit=9223372036854775807)\n",
      " |      Behaves like the built-in str.split() except returns a\n",
      " |      WordList.\n",
      " |      \n",
      " |      :rtype: :class:`WordList <WordList>`\n",
      " |  \n",
      " |  subjectivity = <textblob.decorators.cached_property object>\n",
      " |  tags = <textblob.decorators.cached_property object>\n",
      " |  tokenize(self, tokenizer=None)\n",
      " |      Return a list of tokens, using ``tokenizer``.\n",
      " |      \n",
      " |      :param tokenizer: (optional) A tokenizer object. If None, defaults to\n",
      " |          this blob's default tokenizer.\n",
      " |  \n",
      " |  tokens = <textblob.decorators.cached_property object>\n",
      " |  translate(self, from_lang='auto', to='en')\n",
      " |      Translate the blob to another language.\n",
      " |      Uses the Google Translate API. Returns a new TextBlob.\n",
      " |      \n",
      " |      Requires an internet connection.\n",
      " |      \n",
      " |      Usage:\n",
      " |      ::\n",
      " |      \n",
      " |          >>> b = TextBlob(\"Simple is better than complex\")\n",
      " |          >>> b.translate(to=\"es\")\n",
      " |          TextBlob('Lo simple es mejor que complejo')\n",
      " |      \n",
      " |      Language code reference:\n",
      " |          https://developers.google.com/translate/v2/using_rest#language-params\n",
      " |      \n",
      " |      .. versionadded:: 0.5.0.\n",
      " |      \n",
      " |      :param str from_lang: Language to translate from. If ``None``, will attempt\n",
      " |          to detect the language.\n",
      " |      :param str to: Language to translate to.\n",
      " |      :rtype: :class:`BaseBlob <BaseBlob>`\n",
      " |  \n",
      " |  word_counts = <textblob.decorators.cached_property object>\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from BaseBlob:\n",
      " |  \n",
      " |  analyzer = <textblob.en.sentiments.PatternAnalyzer object>\n",
      " |  \n",
      " |  np_extractor = <textblob.en.np_extractors.FastNPExtractor object>\n",
      " |  \n",
      " |  parser = <textblob.en.parsers.PatternParser object>\n",
      " |  \n",
      " |  pos_tagger = <textblob.en.taggers.NLTKTagger object>\n",
      " |  \n",
      " |  tokenizer = <textblob.tokenizers.WordTokenizer object>\n",
      " |  \n",
      " |  translator = <textblob.translate.Translator object>\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from textblob.mixins.StringlikeMixin:\n",
      " |  \n",
      " |  __contains__(self, sub)\n",
      " |      Implements the `in` keyword like a Python string.\n",
      " |  \n",
      " |  __getitem__(self, index)\n",
      " |      Returns a  substring. If index is an integer, returns a Python\n",
      " |      string of a single character. If a range is given, e.g. `blob[3:5]`,\n",
      " |      a new instance of the class is returned.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |      Makes the object iterable as if it were a string,\n",
      " |      iterating through the raw string's characters.\n",
      " |  \n",
      " |  __len__(self)\n",
      " |      Returns the length of the raw text.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Returns a string representation for debugging.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Returns a string representation used in print statements\n",
      " |      or str(my_blob).\n",
      " |  \n",
      " |  ends_with = endswith(self, suffix, start=0, end=9223372036854775807)\n",
      " |  \n",
      " |  endswith(self, suffix, start=0, end=9223372036854775807)\n",
      " |      Returns True if the blob ends with the given suffix.\n",
      " |  \n",
      " |  find(self, sub, start=0, end=9223372036854775807)\n",
      " |      Behaves like the built-in str.find() method. Returns an integer,\n",
      " |      the index of the first occurrence of the substring argument sub in the\n",
      " |      sub-string given by [start:end].\n",
      " |  \n",
      " |  format(self, *args, **kwargs)\n",
      " |      Perform a string formatting operation, like the built-in\n",
      " |      `str.format(*args, **kwargs)`. Returns a blob object.\n",
      " |  \n",
      " |  index(self, sub, start=0, end=9223372036854775807)\n",
      " |      Like blob.find() but raise ValueError when the substring\n",
      " |      is not found.\n",
      " |  \n",
      " |  join(self, iterable)\n",
      " |      Behaves like the built-in `str.join(iterable)` method, except\n",
      " |      returns a blob object.\n",
      " |      \n",
      " |      Returns a blob which is the concatenation of the strings or blobs\n",
      " |      in the iterable.\n",
      " |  \n",
      " |  lower(self)\n",
      " |      Like str.lower(), returns new object with all lower-cased characters.\n",
      " |  \n",
      " |  replace(self, old, new, count=9223372036854775807)\n",
      " |      Return a new blob object with all the occurence of `old` replaced\n",
      " |      by `new`.\n",
      " |  \n",
      " |  rfind(self, sub, start=0, end=9223372036854775807)\n",
      " |      Behaves like the built-in str.rfind() method. Returns an integer,\n",
      " |      the index of he last (right-most) occurence of the substring argument\n",
      " |      sub in the sub-sequence given by [start:end].\n",
      " |  \n",
      " |  rindex(self, sub, start=0, end=9223372036854775807)\n",
      " |      Like blob.rfind() but raise ValueError when substring is not\n",
      " |      found.\n",
      " |  \n",
      " |  starts_with = startswith(self, prefix, start=0, end=9223372036854775807)\n",
      " |  \n",
      " |  startswith(self, prefix, start=0, end=9223372036854775807)\n",
      " |      Returns True if the blob starts with the given prefix.\n",
      " |  \n",
      " |  strip(self, chars=None)\n",
      " |      Behaves like the built-in str.strip([chars]) method. Returns\n",
      " |      an object with leading and trailing whitespace removed.\n",
      " |  \n",
      " |  title(self)\n",
      " |      Returns a blob object with the text in title-case.\n",
      " |  \n",
      " |  upper(self)\n",
      " |      Like str.upper(), returns new object with all upper-cased characters.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from textblob.mixins.StringlikeMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from textblob.mixins.ComparableMixin:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ge__(self, other)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __gt__(self, other)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __le__(self, other)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __lt__(self, other)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __ne__(self, other)\n",
      " |      Return self!=value.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hi', 'NNP'),\n",
       " ('please', 'NN'),\n",
       " ('like', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('video', 'NN')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['hi'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb.noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.0, subjectivity=0.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb = blob('I love this channel. there is many useful videos are here!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-Time Voice Recording "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run these files in conda otherwise you might get error\n",
    "#Watch video on this here \n",
    "#https://youtu.be/BSpRLtHGUDQ\n",
    "# pip install SpeechRecognition\n",
    "# conda install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say Something...\n",
      "these people are really very poor and I am going to kill everybody I I main they don't deserve to live in this country and then either deserve to live on the planet Earth\n",
      "Sentiment(polarity=-0.02015151515151517, subjectivity=0.5283333333333333)\n"
     ]
    }
   ],
   "source": [
    "with sr.Microphone() as source:\n",
    "    print('Say Something...')\n",
    "    audio = r.listen(source, timeout=2)\n",
    "    try:\n",
    "        text = r.recognize_google(audio)\n",
    "        tb = blob(text)\n",
    "        print(text)\n",
    "        print(tb.sentiment)\n",
    "    except:\n",
    "        print('Sorry... Try again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Say Something...\n",
      "hello hi baby what's up I am missing you so much\n",
      "Sentiment(polarity=0.0, subjectivity=0.125)\n",
      "\n",
      "Say Something...\n",
      "do you know I love you so much and have anyone told you that you are the one of the most beautiful girl in the world\n",
      "Sentiment(polarity=0.5125, subjectivity=0.575)\n",
      "\n",
      "Say Something...\n",
      "ok so have you are you done with your dinner are you going to have your dinner\n",
      "Sentiment(polarity=0.5, subjectivity=0.5)\n",
      "\n",
      "Say Something...\n",
      "Informatica ok one thing do you know we we have a lot of the things common in between us we like like romantic movies and and you books except Raso these are the really great things between us\n",
      "Sentiment(polarity=0.25, subjectivity=0.5625)\n",
      "\n",
      "Say Something...\n",
      "yes you are right my apology but do not there to tell me again otherwise I'll kill you also that you ok I also you with the gun in your head and in your heart and don't dare to talk to me like this ever\n",
      "Sentiment(polarity=0.39285714285714285, subjectivity=0.5178571428571428)\n",
      "\n",
      "Say Something...\n",
      "but still I love you so much I hate you don't talk to me like this and I'll never call you back\n",
      "Sentiment(polarity=-0.10000000000000002, subjectivity=0.5)\n",
      "\n",
      "Say Something...\n",
      "online now you see here in this sentence when I say that but still I love you so much I hate you and don't talk to me like this and I'll never call you now you can see here there is a negativity in this sentence and it is saying that yes there is any creativity in this sentence super have some 123456 and the 7th 7th time running so what I am talking here its Guna of course printed so let's get it printed and then we'll talk again\n",
      "Sentiment(polarity=0.01111111111111109, subjectivity=0.7222222222222222)\n",
      "\n",
      "Say Something...\n",
      "Sorry... Try again\n",
      "\n",
      "Say Something...\n",
      "kidding and please do not mind I love you 3000 even I love you goodnight\n",
      "Sentiment(polarity=0.5, subjectivity=0.6)\n",
      "\n",
      "Say Something...\n",
      "ok now you see here so this is there is polarity at this the positivity Heera 20.5 so this is how you see here our phone call is being converted into word text by using this lesson tutorial you can go and watch speech recognition in Python speed detection in Python at KGP talking you can search and you can get this otherwise I have already given the link for this this listen here you can watch from here as well here\n",
      "Sentiment(polarity=0.5, subjectivity=0.5)\n"
     ]
    }
   ],
   "source": [
    "iter_num = 10\n",
    "index = 0\n",
    "while(index<iter_num):\n",
    "    with sr.Microphone() as source:\n",
    "        print()\n",
    "        print('Say Something...')\n",
    "        audio = r.listen(source, timeout=3)\n",
    "        try:\n",
    "            text = r.recognize_google(audio)\n",
    "            tb = blob(text)\n",
    "            print(text)\n",
    "            print(tb.sentiment)\n",
    "        except:\n",
    "            print('Sorry... Try again')\n",
    "        index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
